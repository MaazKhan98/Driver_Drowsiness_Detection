{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2 \n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42  #setting the random variable value for reobataining the variable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data_train = os.path.join('dataset/'+'eyes_only/train')  #defining the path where dataset is stored\n",
    "image_data_test = os.path.join('dataset/'+'eyes_only/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1/255,\n",
    "                                zoom_range=0.2,\n",
    "                                shear_range=0.4,\n",
    "                                horizontal_flip=True,\n",
    "                                rotation_range=40,\n",
    "                                fill_mode='nearest',\n",
    "                                brightness_range=[0.2,1])\n",
    "\n",
    "test_gen = ImageDataGenerator(rescale=1/255)      #data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1234 images belonging to 2 classes.\nFound 218 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_gen.flow_from_directory(image_data_train,\n",
    "                                          target_size=(128,128),\n",
    "                                          shuffle=True,\n",
    "                                          batch_size=25,\n",
    "                                          class_mode='binary')\n",
    "test_set = test_gen.flow_from_directory(image_data_test,\n",
    "                                        class_mode='binary',\n",
    "                                        shuffle=False,\n",
    "                                        target_size=(128,128),\n",
    "                                        batch_size=15)   \n",
    "# Date Preprocessing                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Conv2D, MaxPooling2D,Flatten,BatchNormalization,Dropout,Dense\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping\n",
    "from keras.applications import VGG16,ResNet50V2,xception,inception_v3\n",
    "from livelossplot import PlotLossesKeras\n",
    "import pydot\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_model():\n",
    "    model_cnn = Sequential()\n",
    "    model_cnn.add(Conv2D(64,(3,3),input_shape=(128,128,3),padding='same',activation='relu'))\n",
    "    model_cnn.add(MaxPooling2D(pool_size=(3,3)))\n",
    "    model_cnn.add(Conv2D(64,(3,3),activation='relu',padding='valid'))\n",
    "    model_cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model_cnn.add(BatchNormalization())\n",
    "    model_cnn.add(Conv2D(32,(3,3),activation='relu',padding='valid'))\n",
    "    model_cnn.add(MaxPooling2D(2,2))\n",
    "    model_cnn.add(Conv2D(32,(3,3),activation='relu',padding='valid'))\n",
    "    model_cnn.add(MaxPooling2D(2,2))\n",
    "    model_cnn.add(BatchNormalization())\n",
    "    model_cnn.add(Flatten())\n",
    "\n",
    "    model_cnn.add(Dense(512,activation='relu'))\n",
    "    model_cnn.add(Dense(64,activation='relu'))\n",
    "    model_cnn.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "    model_cnn.compile(optimizer='adam',metrics=['accuracy'],loss='binary_crossentropy')\n",
    "    \n",
    "\n",
    "    return model_cnn\n",
    "\n",
    "    #defining a function that will return model (sequential) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_5\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_17 (Conv2D)           (None, 128, 128, 64)      1792      \n_________________________________________________________________\nmax_pooling2d_17 (MaxPooling (None, 42, 42, 64)        0         \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 40, 40, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_18 (MaxPooling (None, 20, 20, 64)        0         \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 20, 20, 64)        256       \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 18, 18, 32)        18464     \n_________________________________________________________________\nmax_pooling2d_19 (MaxPooling (None, 9, 9, 32)          0         \n_________________________________________________________________\nconv2d_20 (Conv2D)           (None, 7, 7, 32)          9248      \n_________________________________________________________________\nmax_pooling2d_20 (MaxPooling (None, 3, 3, 32)          0         \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 3, 3, 32)          128       \n_________________________________________________________________\nflatten_5 (Flatten)          (None, 288)               0         \n_________________________________________________________________\ndense_13 (Dense)             (None, 512)               147968    \n_________________________________________________________________\ndense_14 (Dense)             (None, 64)                32832     \n_________________________________________________________________\ndense_15 (Dense)             (None, 1)                 65        \n=================================================================\nTotal params: 247,681\nTrainable params: 247,489\nNon-trainable params: 192\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = call_model()\n",
    "#plot_model(model,to_file='model_cnn_1.png',show_shapes=True,show_layer_names=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "49/49 [==============================] - 12s 250ms/step - loss: 0.2128 - accuracy: 0.9074 - val_loss: 1.2124 - val_accuracy: 0.5571\n",
      "Epoch 2/10\n",
      "49/49 [==============================] - 8s 164ms/step - loss: 0.1227 - accuracy: 0.9537 - val_loss: 1.4494 - val_accuracy: 0.6749\n",
      "Epoch 3/10\n",
      "49/49 [==============================] - 8s 157ms/step - loss: 0.1110 - accuracy: 0.9537 - val_loss: 1.5804 - val_accuracy: 0.6798\n",
      "Epoch 4/10\n",
      "49/49 [==============================] - 8s 154ms/step - loss: 0.0793 - accuracy: 0.9719 - val_loss: 1.7686 - val_accuracy: 0.6798\n",
      "Epoch 5/10\n",
      "49/49 [==============================] - 8s 155ms/step - loss: 0.0971 - accuracy: 0.9620 - val_loss: 0.2032 - val_accuracy: 0.8867\n",
      "Epoch 6/10\n",
      "49/49 [==============================] - 7s 153ms/step - loss: 0.0788 - accuracy: 0.9628 - val_loss: 1.2546 - val_accuracy: 0.8128\n",
      "Epoch 7/10\n",
      "49/49 [==============================] - 8s 155ms/step - loss: 0.0741 - accuracy: 0.9686 - val_loss: 0.7602 - val_accuracy: 0.9458\n",
      "Epoch 8/10\n",
      "49/49 [==============================] - 8s 155ms/step - loss: 0.0550 - accuracy: 0.9793 - val_loss: 0.0011 - val_accuracy: 0.9557\n",
      "Epoch 9/10\n",
      "49/49 [==============================] - 8s 155ms/step - loss: 0.0745 - accuracy: 0.9744 - val_loss: 0.0032 - val_accuracy: 0.9409\n",
      "Epoch 10/10\n",
      "49/49 [==============================] - 7s 152ms/step - loss: 0.0448 - accuracy: 0.9892 - val_loss: 0.0035 - val_accuracy: 0.9507\n"
     ]
    }
   ],
   "source": [
    "h = model.fit(train_set,\n",
    "              steps_per_epoch=train_set.n//25,\n",
    "              epochs=10,\n",
    "              validation_steps=test_set.n//15,\n",
    "              validation_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/model_cnn_1.h5') #saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}